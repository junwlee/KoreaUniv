{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.600603Z",
     "start_time": "2024-04-11T08:38:18.045962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  class  \n",
      "0                          3.92   1065.0      0  \n",
      "1                          3.40   1050.0      0  \n",
      "2                          3.17   1185.0      0  \n",
      "3                          3.45   1480.0      0  \n",
      "4                          2.93    735.0      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data_wine = load_wine()\n",
    "df_wine = pd.DataFrame(data_wine.data, columns=data_wine.feature_names)\n",
    "df_wine['class'] = data_wine.target\n",
    "print(df_wine.head())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, :-1].values, df_wine.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, stratify=y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.628987Z",
     "start_time": "2024-04-11T08:38:18.601817Z"
    }
   },
   "id": "39fe9f362f27adee",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.632738Z",
     "start_time": "2024-04-11T08:38:18.629783Z"
    }
   },
   "id": "2ffc3223c5b0dc8d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr1_10 = LogisticRegression(penalty='l1', C=10.0, solver='liblinear', max_iter=1000) # strength = 0.1\n",
    "lr1_1 = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', max_iter=1000) # strength = 1.0\n",
    "lr1_0_1 = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=1000) # strength = 10.0\n",
    "\n",
    "lr2_10 = LogisticRegression(penalty='l2', C=10.0) # strength = 0.1 (lbfgs is default and supports l2)\n",
    "lr2_1 = LogisticRegression(penalty='l2', C=1.0) # strength = 1.0\n",
    "lr2_0_1 = LogisticRegression(penalty='l2', C=0.1) # strength = 10.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.658401Z",
     "start_time": "2024-04-11T08:38:18.633490Z"
    }
   },
   "id": "7d3950b0e37b0c67",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy with L1 and strength = 0.1: 1.0\n",
      "Test set accuracy with L1 and strength = 0.1: 0.9259259259259259\n",
      "Training set accuracy with L1 and strength = 1.0: 0.9838709677419355\n",
      "Test set accuracy with L1 and strength = 1.0: 0.9444444444444444\n",
      "Training set accuracy with L1 and strength = 10.0: 0.9435483870967742\n",
      "Test set accuracy with L1 and strength = 10.0: 0.8518518518518519\n",
      "Training set accuracy with L2 and strength = 0.1: 0.9919354838709677\n",
      "Test set accuracy with L2 and strength = 0.1: 0.9259259259259259\n",
      "Training set accuracy with L2 and strength = 1.0: 0.9838709677419355\n",
      "Test set accuracy with L2 and strength = 1.0: 0.8888888888888888\n",
      "Training set accuracy with L2 and strength = 10.0: 0.967741935483871\n",
      "Test set accuracy with L2 and strength = 10.0: 0.9259259259259259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr1_10.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L1 and strength = 0.1: {lr1_10.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L1 and strength = 0.1: {lr1_10.score(X_test, y_test)}')\n",
    "\n",
    "lr1_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L1 and strength = 1.0: {lr1_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L1 and strength = 1.0: {lr1_1.score(X_test, y_test)}')\n",
    "\n",
    "lr1_0_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L1 and strength = 10.0: {lr1_0_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L1 and strength = 10.0: {lr1_0_1.score(X_test, y_test)}')\n",
    "\n",
    "lr2_10.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L2 and strength = 0.1: {lr2_10.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L2 and strength = 0.1: {lr2_10.score(X_test, y_test)}')\n",
    "\n",
    "lr2_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L2 and strength = 1.0: {lr2_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L2 and strength = 1.0: {lr2_1.score(X_test, y_test)}')\n",
    "\n",
    "lr2_0_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L2 and strength = 10.0: {lr2_0_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L2 and strength = 10.0: {lr2_0_1.score(X_test, y_test)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.708355Z",
     "start_time": "2024-04-11T08:38:18.659719Z"
    }
   },
   "id": "a7dbad3e9a3df1bb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[[-0.73088515  1.92488361  9.43073307 -2.01750749 -0.09428597  0.\n",
      "   2.93027036  0.          0.         -0.47796258  0.          0.81671687\n",
      "   0.0304905 ]\n",
      " [ 1.18085372 -1.26240364 -6.21557596  0.63087719  0.09862549  0.\n",
      "   3.24040231 11.36292035  0.15825047 -3.69080366  6.10173371  0.\n",
      "  -0.03269244]\n",
      " [ 0.          0.17878015  0.          0.23403161  0.01861623 -4.05726698\n",
      "  -5.91591516  0.          0.          1.68938163  0.         -4.16812709\n",
      "   0.01137639]]\n",
      "[[-0.73088515  1.92488361  9.43073307 -2.01750749 -0.09428597  0.\n",
      "   2.93027036  0.          0.         -0.47796258  0.          0.81671687\n",
      "   0.0304905 ]\n",
      " [ 1.18085372 -1.26240364 -6.21557596  0.63087719  0.09862549  0.\n",
      "   3.24040231 11.36292035  0.15825047 -3.69080366  6.10173371  0.\n",
      "  -0.03269244]\n",
      " [ 0.          0.17878015  0.          0.23403161  0.01861623 -4.05726698\n",
      "  -5.91591516  0.          0.          1.68938163  0.         -4.16812709\n",
      "   0.01137639]]\n",
      "[[-0.73088515  1.92488361  9.43073307 -2.01750749 -0.09428597  0.\n",
      "   2.93027036  0.          0.         -0.47796258  0.          0.81671687\n",
      "   0.0304905 ]\n",
      " [ 1.18085372 -1.26240364 -6.21557596  0.63087719  0.09862549  0.\n",
      "   3.24040231 11.36292035  0.15825047 -3.69080366  6.10173371  0.\n",
      "  -0.03269244]\n",
      " [ 0.          0.17878015  0.          0.23403161  0.01861623 -4.05726698\n",
      "  -5.91591516  0.          0.          1.68938163  0.         -4.16812709\n",
      "   0.01137639]]\n"
     ]
    }
   ],
   "source": [
    "print(lr1_10.intercept_)\n",
    "print(lr1_1.intercept_)\n",
    "print(lr1_0_1.intercept_)\n",
    "\n",
    "print(lr1_10.coef_)\n",
    "print(lr1_10.coef_)\n",
    "print(lr1_10.coef_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.711415Z",
     "start_time": "2024-04-11T08:38:18.709061Z"
    }
   },
   "id": "eaa5d8a30b7b7f19",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0420192   0.18258387 -0.14056467]\n",
      "[-0.02195313  0.0698339  -0.04788077]\n",
      "[-0.0155198   0.0363954  -0.02087561]\n",
      "[[ 0.14060934  0.44184581  0.31254485 -0.45770297 -0.07904206  0.48585057\n",
      "   1.06584447 -0.10930014  0.31905325  0.2814524   0.01630629  0.85016889\n",
      "   0.01061217]\n",
      " [ 1.06722044 -1.3314282  -0.32248615  0.28400245  0.01804413  0.8058247\n",
      "   0.96958004  0.19976329  0.55912209 -2.25120442  0.59029676  0.92077358\n",
      "  -0.0203608 ]\n",
      " [-1.20782978  0.88958239  0.0099413   0.17370052  0.06099793 -1.29167527\n",
      "  -2.03542451 -0.09046315 -0.87817534  1.96975201 -0.60660306 -1.77094247\n",
      "   0.00974864]]\n",
      "[[ 0.14060934  0.44184581  0.31254485 -0.45770297 -0.07904206  0.48585057\n",
      "   1.06584447 -0.10930014  0.31905325  0.2814524   0.01630629  0.85016889\n",
      "   0.01061217]\n",
      " [ 1.06722044 -1.3314282  -0.32248615  0.28400245  0.01804413  0.8058247\n",
      "   0.96958004  0.19976329  0.55912209 -2.25120442  0.59029676  0.92077358\n",
      "  -0.0203608 ]\n",
      " [-1.20782978  0.88958239  0.0099413   0.17370052  0.06099793 -1.29167527\n",
      "  -2.03542451 -0.09046315 -0.87817534  1.96975201 -0.60660306 -1.77094247\n",
      "   0.00974864]]\n",
      "[[ 0.14060934  0.44184581  0.31254485 -0.45770297 -0.07904206  0.48585057\n",
      "   1.06584447 -0.10930014  0.31905325  0.2814524   0.01630629  0.85016889\n",
      "   0.01061217]\n",
      " [ 1.06722044 -1.3314282  -0.32248615  0.28400245  0.01804413  0.8058247\n",
      "   0.96958004  0.19976329  0.55912209 -2.25120442  0.59029676  0.92077358\n",
      "  -0.0203608 ]\n",
      " [-1.20782978  0.88958239  0.0099413   0.17370052  0.06099793 -1.29167527\n",
      "  -2.03542451 -0.09046315 -0.87817534  1.96975201 -0.60660306 -1.77094247\n",
      "   0.00974864]]\n"
     ]
    }
   ],
   "source": [
    "print(lr2_10.intercept_)\n",
    "print(lr2_1.intercept_)\n",
    "print(lr2_0_1.intercept_)\n",
    "\n",
    "print(lr2_10.coef_)\n",
    "print(lr2_10.coef_)\n",
    "print(lr2_10.coef_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.714451Z",
     "start_time": "2024-04-11T08:38:18.712006Z"
    }
   },
   "id": "2429fe7d1d98e970",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Error record\n",
    "\n",
    "1. ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
    "    - 데이터의 분할 방식에서 문제발생\n",
    "    - DataFrame의 구조를 잘 알아야 한다.\n",
    "\n",
    "2. ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "    - lbfgs 솔버가 설정된 최대 반복 횟수에 도달했지만, 최적의 모델 매개변수를 찾기에 충분하지 않았음을 의미\n",
    "    - 이 문제를 해결하기 위해 두 가지 방법을 시도할 수 있다:\n",
    "        - 반복 횟수 증가: max_iter 매개변수의 값을 증가시켜, 솔버가 수렴할 충분한 시간을 제공.\n",
    "        - 데이터 스케일링: 데이터의 스케일(범위)이 너무 다르면 최적화 과정에서 수렴이 어려워질 수 있기 때문에, StandardScaler 같은 방법을 사용하여 데이터의 스케일을 조정할 수 있다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a5c435b5930e6dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline # 데이터 스케일링과 모델을 파이프라인으로 \"연결\"\n",
    "\n",
    "lr1_10 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=10.0, solver='liblinear', max_iter=1000))\n",
    "lr1_1 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=1.0, solver='liblinear', max_iter=1000))\n",
    "lr1_0_1 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=1000))\n",
    "\n",
    "lr2_10 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', C=10.0))\n",
    "lr2_1 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', C=1.0))\n",
    "lr2_0_1 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', C=0.1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.718919Z",
     "start_time": "2024-04-11T08:38:18.715056Z"
    }
   },
   "id": "d08c22516daab21b",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 전처리 (스케일링): \n",
    "- StandardScaler를 통한 데이터 스케일링은 모델 성능에 크게 기여할 수 있다. \n",
    "- 로지스틱 회귀에서는 특성의 스케일이 모델의 성능에 중요한 영향을 미치므로, 스케일링이 모델이 데이터의 패턴을 더 잘 이해하고 학습하는 데 도움을 준 것으로 추정."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7337b2f8a35dcead"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy with L1 and strength = 0.1: 1.0\n",
      "Test set accuracy with L1 and strength = 0.1: 1.0\n",
      "Training set accuracy with L1 and strength = 1.0: 1.0\n",
      "Test set accuracy with L1 and strength = 1.0: 1.0\n",
      "Training set accuracy with L1 and strength = 10.0: 0.9758064516129032\n",
      "Test set accuracy with L1 and strength = 10.0: 0.9629629629629629\n",
      "Training set accuracy with L2 and strength = 0.1: 1.0\n",
      "Test set accuracy with L2 and strength = 0.1: 1.0\n",
      "Training set accuracy with L2 and strength = 1.0: 1.0\n",
      "Test set accuracy with L2 and strength = 1.0: 1.0\n",
      "Training set accuracy with L2 and strength = 10.0: 1.0\n",
      "Test set accuracy with L2 and strength = 10.0: 1.0\n"
     ]
    }
   ],
   "source": [
    "lr1_10.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L1 and strength = 0.1: {lr1_10.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L1 and strength = 0.1: {lr1_10.score(X_test, y_test)}')\n",
    "\n",
    "lr1_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L1 and strength = 1.0: {lr1_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L1 and strength = 1.0: {lr1_1.score(X_test, y_test)}')\n",
    "\n",
    "lr1_0_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L1 and strength = 10.0: {lr1_0_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L1 and strength = 10.0: {lr1_0_1.score(X_test, y_test)}')\n",
    "\n",
    "lr2_10.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L2 and strength = 0.1: {lr2_10.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L2 and strength = 0.1: {lr2_10.score(X_test, y_test)}')\n",
    "\n",
    "lr2_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L2 and strength = 1.0: {lr2_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L2 and strength = 1.0: {lr2_1.score(X_test, y_test)}')\n",
    "\n",
    "lr2_0_1.fit(X_train, y_train)\n",
    "print(f'Training set accuracy with L2 and strength = 10.0: {lr2_0_1.score(X_train, y_train)}')\n",
    "print(f'Test set accuracy with L2 and strength = 10.0: {lr2_0_1.score(X_test, y_test)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:38:18.734102Z",
     "start_time": "2024-04-11T08:38:18.719599Z"
    }
   },
   "id": "eac6b7e497297445",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
