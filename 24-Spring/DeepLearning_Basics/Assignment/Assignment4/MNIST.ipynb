{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Load",
   "id": "ee1a07fb5c293447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:41:14.028959Z",
     "start_time": "2024-06-01T10:41:13.849748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# print(x_train.shape)\n",
    "x_train = np.expand_dims(np.resize(x_train, (x_train.shape[0], 32, 32)), axis=-1)\n",
    "x_test = np.expand_dims(np.resize(x_test, (x_test.shape[0], 32, 32)), axis=-1)\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ],
   "id": "144e22a7246ec62b",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set pretrained model",
   "id": "9ac368846765712"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T11:01:39.069349Z",
     "start_time": "2024-06-01T11:01:38.554076Z"
    }
   },
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_tensor=input_tensor\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "preds = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "# # 기본 모델의 가중치 고정\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# 특정 층부터 학습 가능하게 설정\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# model.summary()"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Compile",
   "id": "71478e4693d49692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T11:01:41.495564Z",
     "start_time": "2024-06-01T11:01:41.488989Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
   "id": "4da79ea065773be6",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model fit",
   "id": "ee1e18ac69509ccf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T11:16:09.361869Z",
     "start_time": "2024-06-01T11:15:31.013612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 흑백 이미지를 3채널로 변경\n",
    "x_train_rgb = np.concatenate([x_train, x_train, x_train], axis=-1)\n",
    "x_test_rgb = np.concatenate([x_test, x_test, x_test], axis=-1)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(\n",
    "    datagen.flow(x_train_rgb, y_train, batch_size=128),\n",
    "    validation_data=(x_test_rgb, y_test),\n",
    "    steps_per_epoch=len(x_train) // 128,\n",
    "    epochs=10\n",
    ")"
   ],
   "id": "d1d64ccf49393998",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 20:15:31.334443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/468 [>.............................] - ETA: 8:37 - loss: 2.3722 - accuracy: 0.1106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[90], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m x_test_rgb \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([x_test, x_test, x_test], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# 모델 훈련\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m     17\u001B[0m     datagen\u001B[38;5;241m.\u001B[39mflow(x_train_rgb, y_train, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m),\n\u001B[1;32m     18\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39m(x_test_rgb, y_test),\n\u001B[1;32m     19\u001B[0m     steps_per_epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(x_train) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m128\u001B[39m,\n\u001B[1;32m     20\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m\n\u001B[1;32m     21\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/keras/engine/training.py:1685\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1678\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1679\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1683\u001B[0m ):\n\u001B[1;32m   1684\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1685\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1687\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    891\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 894\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    896\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    897\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    923\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    924\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    925\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 926\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    927\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    928\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    929\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    930\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    141\u001B[0m   (concrete_function,\n\u001B[1;32m    142\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\u001B[38;5;241m.\u001B[39m_call_flat(\n\u001B[1;32m    144\u001B[0m     filtered_flat_args, captured_inputs\u001B[38;5;241m=\u001B[39mconcrete_function\u001B[38;5;241m.\u001B[39mcaptured_inputs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1753\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1755\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1756\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1757\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mcall(\n\u001B[1;32m   1758\u001B[0m       ctx, args, cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager))\n\u001B[1;32m   1759\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1760\u001B[0m     args,\n\u001B[1;32m   1761\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1762\u001B[0m     executing_eagerly)\n\u001B[1;32m   1763\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    380\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 381\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[1;32m    382\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    383\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m    384\u001B[0m         inputs\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m    385\u001B[0m         attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[1;32m    386\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx)\n\u001B[1;32m    387\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    388\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    389\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    390\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    393\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    394\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocess",
   "id": "e09a8e46cd8b8ba1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:59:28.191086Z",
     "start_time": "2024-06-01T10:59:28.141051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "    img = cv.resize(img, (32, 32))\n",
    "    img = img.astype('float32')\n",
    "    img = img.reshape(32, 32, 1)\n",
    "    # img = 255 - img\n",
    "    img /= 255.0\n",
    "    img = np.concatenate([img, img, img], axis=-1)  # 3채널로 변환\n",
    "    img = img.reshape(1, 32, 32, 3)\n",
    "\n",
    "    return img\n",
    "\n",
    "img_path = 'handwriting/6.png'\n",
    "image = preprocess_image(img_path)  # 전처리된 이미지 얻기\n",
    "\n",
    "plt.imshow(image.reshape(32, 32, 3))\n",
    "plt.show()"
   ],
   "id": "d3b5ede7295672e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict",
   "id": "e2da4d1ac0486cd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:59:31.696716Z",
     "start_time": "2024-06-01T10:59:31.439764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def predict_image(model, image):\n",
    "    return model(image)  # model.predict가 아니라 model(image)를 호출\n",
    "\n",
    "pred = predict_image(model, image)  # 전처리된 이미지를 모델에 전달하여 예측\n",
    "print(pred)\n",
    "print(f'predicted number = {pred.numpy().argmax()}')"
   ],
   "id": "8591ad5159f27926",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.4508456e-02 5.6232023e-01 1.0154590e-01 3.3823490e-02 1.0828131e-03\n",
      "  3.9525967e-02 1.1630969e-01 9.7853437e-02 3.2523800e-02 5.0632231e-04]], shape=(1, 10), dtype=float32)\n",
      "predicted number = 1\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1011e746ab0de67e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
