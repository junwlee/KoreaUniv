{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, AveragePooling2D, MaxPooling2D, Flatten, Dense"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T02:40:35.486999Z",
     "start_time": "2024-06-02T02:40:33.305190Z"
    }
   },
   "id": "a69b0e1c05c41144",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T02:40:36.473262Z",
     "start_time": "2024-06-02T02:40:36.470159Z"
    }
   },
   "source": [
    "def bottleneck_residual_block(X, kernel_size, filters, reduce=False, s=2):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    if reduce:\n",
    "        X_shortcut = Conv2D(filters = F3, kernel_size=(1,1), strides = (s, s)) (X_shortcut)\n",
    "        X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "        \n",
    "        # sets the strides of the first convolutional layer to be similar to the shortcut strides\n",
    "        X = Conv2D(filters = F1, kernel_size=(1,1), strides=(s, s), padding='valid')(X)\n",
    "        X = BatchNormalization(axis=3)(X)\n",
    "        X = Activation('relu')(X)\n",
    "    \n",
    "    else:\n",
    "        # First component of main path\n",
    "        X = Conv2D(filters = F1, kernel_size=(1,1), strides=(1, 1), padding='valid')(X)\n",
    "        X = BatchNormalization(axis=3)(X)\n",
    "        X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size=kernel_size, strides=(1, 1), padding='same')()\n",
    "    X = BatchNormalization(axis=3) (X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size=(1, 1), strides=(1, 1), padding='valid')\n",
    "    X = BatchNormalization(axis=3) (X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Final Step\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BatchNormalization(axis=3)\n",
    "  - axis=3 파라미터는 채널 차원이 입력의 마지막 차원에 위치할 때 사용\n",
    "  - 이미지 데이터의 일반적인 형태는 (배치 크기, 높이, 너비, 채널 수):\n",
    "    - axis=3은 이 채널 차원을 정규화 대상으로 지정"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a70729fdd63cf327"
  },
  {
   "cell_type": "code",
   "source": [
    "def ResNet50(input_shape, classes):\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X_input)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = bottleneck_residual_block(X, 3, [64, 64, 256], reduce=True, s=1)\n",
    "    X = bottleneck_residual_block(X, 3, [64, 64, 256])\n",
    "    X = bottleneck_residual_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    # Stage 3\n",
    "    X = bottleneck_residual_block(X, 3, [128, 128, 512], reduce=True, s=2)\n",
    "    X = bottleneck_residual_block(X, 3, [128, 128, 512])\n",
    "    X = bottleneck_residual_block(X, 3, [128, 128, 512])\n",
    "    X = bottleneck_residual_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4\n",
    "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], reduce=True, s=2)\n",
    "    X = bottleneck_residual_block(X, 3, [256, 256, 1024])\n",
    "    X = bottleneck_residual_block(X, 3, [256, 256, 1024])\n",
    "    X = bottleneck_residual_block(X, 3, [256, 256, 1024])\n",
    "    X = bottleneck_residual_block(X, 3, [256, 256, 1024])\n",
    "    X = bottleneck_residual_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5\n",
    "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], reduce=True, s=2)\n",
    "    X = bottleneck_residual_block(X, 3, [512, 512, 2048])\n",
    "    X = bottleneck_residual_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D((1,1))(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T02:40:39.858973Z",
     "start_time": "2024-06-02T02:40:39.853499Z"
    }
   },
   "id": "d484bfe92819004f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T02:44:36.975579Z",
     "start_time": "2024-06-02T02:44:36.882127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 10\n",
    "\n",
    "model = ResNet50(input_shape=input_shape, classes=classes)\n",
    "\n",
    "model.summary()"
   ],
   "id": "34ed9ae2706d0da1",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m      2\u001B[0m classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m ResNet50(input_shape\u001B[38;5;241m=\u001B[39minput_shape, classes\u001B[38;5;241m=\u001B[39mclasses)\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "Cell \u001B[0;32mIn[3], line 11\u001B[0m, in \u001B[0;36mResNet50\u001B[0;34m(input_shape, classes)\u001B[0m\n\u001B[1;32m      8\u001B[0m X \u001B[38;5;241m=\u001B[39m MaxPooling2D((\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m), strides\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m))(X)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Stage 2\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m X \u001B[38;5;241m=\u001B[39m bottleneck_residual_block(X, \u001B[38;5;241m3\u001B[39m, [\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m256\u001B[39m], reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, s\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     12\u001B[0m X \u001B[38;5;241m=\u001B[39m bottleneck_residual_block(X, \u001B[38;5;241m3\u001B[39m, [\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m256\u001B[39m])\n\u001B[1;32m     13\u001B[0m X \u001B[38;5;241m=\u001B[39m bottleneck_residual_block(X, \u001B[38;5;241m3\u001B[39m, [\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m256\u001B[39m])\n",
      "Cell \u001B[0;32mIn[2], line 22\u001B[0m, in \u001B[0;36mbottleneck_residual_block\u001B[0;34m(X, kernel_size, filters, reduce, s)\u001B[0m\n\u001B[1;32m     19\u001B[0m     X \u001B[38;5;241m=\u001B[39m Activation(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m)(X)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Second component of main path\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m X \u001B[38;5;241m=\u001B[39m Conv2D(filters \u001B[38;5;241m=\u001B[39m F2, kernel_size\u001B[38;5;241m=\u001B[39mkernel_size, strides\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m)()\n\u001B[1;32m     23\u001B[0m X \u001B[38;5;241m=\u001B[39m BatchNormalization(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m) (X)\n\u001B[1;32m     24\u001B[0m X \u001B[38;5;241m=\u001B[39m Activation(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m)(X)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/CV/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/opt/anaconda3/envs/CV/lib/python3.11/site-packages/keras/utils/layer_utils.py:809\u001B[0m, in \u001B[0;36mCallFunctionSpec.split_out_first_arg\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m    807\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_arg_names[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 809\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    810\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe first argument to `Layer.call` must always be passed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    811\u001B[0m     )\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inputs, args, kwargs\n",
      "\u001B[0;31mValueError\u001B[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "\n",
    "reduce_lr= ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=np.sqrt(0.1),\n",
    "    patience=5,\n",
    "    min_lr=0.5e-6\n",
    ")\n",
    "\n",
    "SGD = optimizers.SGD()\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs, callbacks=[reduce_lr])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95907e4b3a86da97",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
