{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the VGG16 Model",
   "id": "99a44564ef57ce5d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T01:13:51.831420Z",
     "start_time": "2024-06-05T01:13:51.670415Z"
    }
   },
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# View the names and output shape",
   "id": "c9f895f4558487b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:13:51.834004Z",
     "start_time": "2024-06-05T01:13:51.832403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    print(f'Layer name: {layer.name}, output_shape: {layer.output.shape}')"
   ],
   "id": "f647e874025b4faa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: block1_conv1, output_shape: (None, None, None, 64)\n",
      "Layer name: block1_conv2, output_shape: (None, None, None, 64)\n",
      "Layer name: block2_conv1, output_shape: (None, None, None, 128)\n",
      "Layer name: block2_conv2, output_shape: (None, None, None, 128)\n",
      "Layer name: block3_conv1, output_shape: (None, None, None, 256)\n",
      "Layer name: block3_conv2, output_shape: (None, None, None, 256)\n",
      "Layer name: block3_conv3, output_shape: (None, None, None, 256)\n",
      "Layer name: block4_conv1, output_shape: (None, None, None, 512)\n",
      "Layer name: block4_conv2, output_shape: (None, None, None, 512)\n",
      "Layer name: block4_conv3, output_shape: (None, None, None, 512)\n",
      "Layer name: block5_conv1, output_shape: (None, None, None, 512)\n",
      "Layer name: block5_conv2, output_shape: (None, None, None, 512)\n",
      "Layer name: block5_conv3, output_shape: (None, None, None, 512)\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gradient ascent process:\n",
    "    - Define a loss function that seeks to maximize the activation of a specific filter (filter _index) in a specific layer (layer_name)"
   ],
   "id": "a48e04fb7490ce9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:13:51.946162Z",
     "start_time": "2024-06-05T01:13:51.834545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 입력 이미지 로드 및 전처리\n",
    "img_path = 'samoyed.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "# print(img_array.shape)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# 지정된 레이어 및 필터 설정\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 127\n",
    "\n",
    "# 그래디언트 테이프 사용\n",
    "with tf.GradientTape() as tape:\n",
    "    # 입력 이미지에 대한 텐서 설정\n",
    "    input_img = tf.convert_to_tensor(img_array)\n",
    "    tape.watch(input_img) # tape 객체가 input_img 텐서를 추적 # 그래디언트를 계산할 때 필요\n",
    "    \n",
    "    # 모델의 출력 얻기\n",
    "    layer_output = model.get_layer(layer_name).output # KerasTensor\n",
    "    model_output = tf.keras.Model(inputs=model.inputs, outputs=layer_output)\n",
    "    layer_output_value = model_output(input_img) # 다양한 레이어 출력에 접근 # EagerTensor\n",
    "    # print(f'layer_output_value.shape: {layer_output_value.shape}')\n",
    "    \n",
    "    # 손실 함수 계산\n",
    "    loss = tf.reduce_mean(layer_output_value[:, :, :, filter_index])\n",
    "    # tf.reduce_mean은 주어진 텐서의 평균 값을 계산하는 함수\n",
    "    # 선택된 필터의 활성화 맵에 대한 평균 값을 계산\n",
    "\n",
    "# 그래디언트 계산\n",
    "grads = tape.gradient(\n",
    "    target=loss,\n",
    "    sources=input_img\n",
    ")\n",
    "# gradient 메서드는 tf.GradientTape 컨텍스트 내에서 기록된 연산을 바탕으로, 주어진 스칼라 텐서(보통 손실 함수)에 대한 하나 이상의 텐서의 그래디언트를 계산\n",
    "\n",
    "# 그래디언트 정규화\n",
    "grads /= (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "\n",
    "# 손실과 그래디언트를 반환하는 함수\n",
    "iterate = tf.function(lambda x: (loss, grads))\n",
    "# tf.function: 반복적인 연산을 효율적으로 처리\n",
    "\n",
    "# 함수 호출\n",
    "# loss_value, grads_value = iterate(input_img)\n",
    "# print('Loss:', loss_value.numpy())\n",
    "# print('Gradients:', grads_value.numpy())"
   ],
   "id": "15c9122a161ed76e",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  tf.GradientTape\n",
    "    - 텐서의 연산을 기록하고, 이 기록을 바탕으로 그래디언트를 자동으로 계산하는 도구\n",
    "        - with 블록 내에서 수행된 연산을 모두 기록\n",
    "    - tf.GradientTape 객체가 텐서로 변환된 img_array를 추적하는 이유는 그래디언트를 계산할 때 이 텐서가 손실 함수에 어떻게 영향을 미치는지 파악하기 위해서\n",
    "        - 입력 이미지가 특정 레이어와 필터의 활성화를 최대화하기 위해 어떻게 변경되어야 하는지 알 수 있다."
   ],
   "id": "f9c97b063b909c8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### tape의 주요 기능과 특징\n",
    "    - 자동 미분: tf.GradientTape는 연산을 기록하고, 이를 바탕으로 미분(그래디언트)을 자동으로 계산\n",
    "    - 컨텍스트 관리: with 블록 안에서 실행된 모든 연산을 기록\n",
    "        - with 블록이 끝나면, tape 객체는 기록된 연산을 바탕으로 그래디언트를 계산\n",
    "    - 다양한 연산 지원: 텐서의 다양한 연산을 지원하며, 특히 딥러닝 모델의 학습 과정에서 손실 함수에 대한 그래디언트를 계산할 때 유용\n",
    "    - 위의 코드에서는 input_img에 대한 손실 함수 loss의 그래디언트를 계산하기 위해 tape 객체를 사용\n",
    "        - 이를 통해 입력 이미지가 특정 레이어와 필터의 활성화를 최대화하도록 조정"
   ],
   "id": "d955c213cc74edb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 그래디언트 계산의 의미\n",
    "    - 손실 함수에 대한 입력 이미지의 그래디언트를 계산함으로써 입력 이미지를 수정할 방향을 알 수 있다."
   ],
   "id": "8a9e5c9871d63451"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Do gradient ascent",
   "id": "f0a13c211bc682c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:15:14.858055Z",
     "start_time": "2024-06-05T01:15:14.855790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_ascent(n_times, input_img, step):\n",
    "    for _ in range(n_times):\n",
    "        loss_value, grads_value = iterate([input_img])\n",
    "        input_img += grads_value * step"
   ],
   "id": "b4342dd9f93edbd6",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert tensor into a valid image",
   "id": "489f29c2f3cd42bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:17:12.771615Z",
     "start_time": "2024-06-05T01:17:12.767995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # # Real Image\n",
    "    # x = x.numpy()  # EagerTensor를 NumPy 배열로 변환\n",
    "\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "    \n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    \n",
    "    # Random Data\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8') # Converts to an RGB array\n",
    "    \n",
    "    # # Real image\n",
    "    # x *= 255\n",
    "    # x = x[0]  # (1, 224, 224, 3)에서 (224, 224, 3)으로 변환\n",
    "    # x = x.astype('uint8')  # uint8로 변환\n",
    "    \n",
    "    return x\n",
    "\n",
    "# 이미지 크기 조정\n",
    "def resize_image(img, scale_factor):\n",
    "    width, height = img.size\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    return img.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "step = 0.1\n",
    "n_times = 20\n",
    "# gradient_ascent(n_times,input_img,step)\n",
    "# \n",
    "# img = deprocess_image(input_img)\n",
    "# img = Image.fromarray(img)\n",
    "# img = resize_image(img, 2)  # 두 배 크기로 조정\n",
    "# img.save('%s_filter_%d_large.png' % (layer_name, filter_index))"
   ],
   "id": "354e307ff2594330",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Data",
   "id": "83ec256d4a62d64f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:23:59.559447Z",
     "start_time": "2024-06-05T01:23:59.531078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import imageio\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "input_img_data = np.random.random((1, img_width, img_height, 3)) * 20 + 128\n",
    "gradient_ascent(n_times, input_img_data, step)\n",
    "random_img = input_img_data[0]\n",
    "random_img = deprocess_image(random_img)\n",
    "imageio.imwrite('%s_filter_%d.png' % (layer_name, filter_index), random_img)"
   ],
   "id": "27d8b207e62e4584",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150528, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[66], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m random_img \u001B[38;5;241m=\u001B[39m random_img\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m50176\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(random_img\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 11\u001B[0m random_img \u001B[38;5;241m=\u001B[39m deprocess_image(random_img)\n\u001B[1;32m     12\u001B[0m imageio\u001B[38;5;241m.\u001B[39mimwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_filter_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (layer_name, filter_index), random_img)\n",
      "Cell \u001B[0;32mIn[57], line 16\u001B[0m, in \u001B[0;36mdeprocess_image\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Random Data\u001B[39;00m\n\u001B[1;32m     15\u001B[0m x \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m\n\u001B[0;32m---> 16\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mtranspose((\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     17\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(x, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# Converts to an RGB array\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# # Real image\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# x *= 255\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# x = x[0]  # (1, 224, 224, 3)에서 (224, 224, 3)으로 변환\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# x = x.astype('uint8')  # uint8로 변환\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: axes don't match array"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e688939ce895d5a2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
