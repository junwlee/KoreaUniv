{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T01:32:29.348552Z",
     "start_time": "2024-06-05T01:32:25.956210Z"
    }
   },
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "# VGG16 모델 로드\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in model.layers:\n",
    "    # Checks for a convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    print(f'Layer name: {layer.name}, output_shape: {layer.output.shape}')\n",
    "\n",
    "# 그래디언트 상승 함수 정의\n",
    "def gradient_ascent(n_times, input_img, step):\n",
    "    for _ in range(n_times):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_img)\n",
    "            layer_output = model.get_layer(layer_name).output\n",
    "            model_output = tf.keras.Model(inputs=model.inputs, outputs=layer_output)\n",
    "            layer_output_value = model_output(input_img)\n",
    "            loss = tf.reduce_mean(layer_output_value[:, :, :, filter_index])\n",
    "        grads = tape.gradient(loss, input_img)\n",
    "        grads /= (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "        input_img.assign_add(grads * step)\n",
    "\n",
    "# 이미지 후처리 함수 정의\n",
    "def deprocess_image(x):\n",
    "    x = x - x.mean()\n",
    "    x = x / (x.std() + 1e-5)\n",
    "    x = x * 0.1\n",
    "    x = x + 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    x = x * 255\n",
    "    x = x.astype('uint8')\n",
    "    return x\n",
    "\n",
    "# 필터 활성화를 위한 레이어와 필터 인덱스 설정\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 127\n",
    "\n",
    "# 입력 이미지 크기 정의\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "# 랜덤 이미지로 필터 활성화 시도\n",
    "input_img_data = tf.Variable(np.random.random((1, img_width, img_height, 3)) * 20 + 128, dtype=tf.float32)\n",
    "\n",
    "step = 0.1\n",
    "n_times = 20\n",
    "gradient_ascent(n_times, input_img_data, step)\n",
    "result_img = input_img_data.numpy()[0]\n",
    "result_img = deprocess_image(result_img)\n",
    "imageio.imwrite('%s_filter_%d.png' % (layer_name, filter_index), result_img)\n",
    "\n",
    "print(\"이미지 생성 완료.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: block1_conv1, output_shape: (None, None, None, 64)\n",
      "Layer name: block1_conv2, output_shape: (None, None, None, 64)\n",
      "Layer name: block2_conv1, output_shape: (None, None, None, 128)\n",
      "Layer name: block2_conv2, output_shape: (None, None, None, 128)\n",
      "Layer name: block3_conv1, output_shape: (None, None, None, 256)\n",
      "Layer name: block3_conv2, output_shape: (None, None, None, 256)\n",
      "Layer name: block3_conv3, output_shape: (None, None, None, 256)\n",
      "Layer name: block4_conv1, output_shape: (None, None, None, 512)\n",
      "Layer name: block4_conv2, output_shape: (None, None, None, 512)\n",
      "Layer name: block4_conv3, output_shape: (None, None, None, 512)\n",
      "Layer name: block5_conv1, output_shape: (None, None, None, 512)\n",
      "Layer name: block5_conv2, output_shape: (None, None, None, 512)\n",
      "Layer name: block5_conv3, output_shape: (None, None, None, 512)\n",
      "이미지 생성 완료.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### tensorflow.Variable",
   "id": "566e1cda6b830163"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Ex1",
   "id": "29dad6d76c15bcd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:53:45.098721Z",
     "start_time": "2024-06-05T01:53:45.092153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.Variable을 사용하여 변수를 생성\n",
    "my_var = tf.Variable([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "\n",
    "# 변수의 값을 출력\n",
    "print(\"Initial value:\", my_var.numpy())\n",
    "\n",
    "# 변수의 값을 수정\n",
    "my_var.assign([4.0, 5.0, 6.0])\n",
    "print(\"Updated value:\", my_var.numpy())\n",
    "\n",
    "# 변수의 값을 증가시킴\n",
    "my_var.assign_add([1.0, 1.0, 1.0])\n",
    "print(\"Incremented value:\", my_var.numpy())\n",
    "\n",
    "# 변수의 값을 감소시킴\n",
    "my_var.assign_sub([2.0, 2.0, 2.0])\n",
    "print(\"Decreased value:\", my_var.numpy())"
   ],
   "id": "ddd3000618fd4ed9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value: [1. 2. 3.]\n",
      "Updated value: [4. 5. 6.]\n",
      "Incremented value: [5. 6. 7.]\n",
      "Decreased value: [3. 4. 5.]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Ex2",
   "id": "c0e80a25f13faf8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T01:57:28.025863Z",
     "start_time": "2024-06-05T01:57:28.014817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 학습 가능한 파라미터를 tf.Variable로 정의\n",
    "W = tf.Variable(tf.random.normal([3, 2]), name='weight')\n",
    "print(\"Initial weights:\", W.numpy())\n",
    "b = tf.Variable(tf.zeros([2]), name='bias')\n",
    "print(\"Initial bias:\", b.numpy())\n",
    "\n",
    "# 간단한 선형 모델 정의\n",
    "def model(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "# 손실 함수 정의 (MSE)\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = tf.optimizers.legacy.SGD(learning_rate=0.01)\n",
    "\n",
    "# 입력 데이터 및 레이블\n",
    "X = tf.constant([[1.0, 2.0, 3.0]], dtype=tf.float32)\n",
    "y_true = tf.constant([[1.0, 2.0]], dtype=tf.float32)\n",
    "\n",
    "# 그래디언트 테이프를 사용하여 학습\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "# 그래디언트 계산 및 적용\n",
    "grads = tape.gradient(loss, [W, b])\n",
    "optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "print(\"Updated weights:\", W.numpy())\n",
    "print(\"Updated bias:\", b.numpy())"
   ],
   "id": "79090b89726a0562",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [[-0.06313162  0.54826355]\n",
      " [ 0.5222686  -0.85945195]\n",
      " [-0.07272832  0.26974446]]\n",
      "Initial bias: [0. 0.]\n",
      "Updated weights: [[-0.06076383  0.5718776 ]\n",
      " [ 0.5270042  -0.8122238 ]\n",
      " [-0.06562494  0.34058666]]\n",
      "Updated bias: [0.00236779 0.02361407]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "39fdbd28becb339b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
